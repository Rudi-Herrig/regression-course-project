---
title: "Project Paper 1"
author: "Rudi Herrig and Jordan Kim"
date: "17 March 2024"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
library(tinytex)
library(readxl)
library(tidyverse)
library(stringr)
library(magrittr)
library(ggplot2)
# install.packages("corrr")
library(corrr)
# install.packages("corrplot")
library(corrplot)

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "100%",fig.align='center')
```

# Also trying with state data rather than county data
```{r}
population <- read_xlsx("USCensus_1840_state.xlsx")
summary(population)
```

```{r}
# I have split our code into chunks to make it easier to see which code does what
# I have also commented the code to make it easier to understand

# 1280 rows
# ADB - production of industries
# ADE - Men employed in selected industries
production <- read_xlsx("USCensus_1840_county.xlsx")
# to check for data structure, `summary(production)` is used

# 1280 rows
# ACX - County Borders Navigable waterway, 1 if yes
navig <- read_xlsx("USCensusData1840.xlsx")
# There was an extra row in `navig` for D.C.'s county of Alexandria (distinct from Rural County of Alexandria) so I removed it.
navig <- navig[-101,]

# 1280 rows
# ADC - Capital Invested
# ADD - Persons Employed
capital <- read_xlsx("USCensusData1840_2.xlsx")
```

```{r}
# bigboy is all the data sets combined
bigboy <- production %>% inner_join(navig) %>% inner_join(capital) 

# bignav is to try to salvage the navigable waterway variable as the response
bignav <- navig %>%  inner_join(capital) %>% inner_join(production)
# I omit all rows with NAs
bignav <- na.omit(bignav)
# bignav has 1257 rows (including Header row) after NA rows are removed
# separating header row to further clean up the data set
bignav_head <- bignav %>% slice_head()
# joiningvariables is the data frame for the rows used for joining (i.e. same as bigboy[,1:9])
joiningvariables <- bignav[-1, 1:9]
# I apply as.numeric and as.integer functions to convert columns to integers
# I apply function to convert only the meaningful portion of our data set, without the header row and the non-meaningful (identifying) columns of the data set.
bignavnumconv <- as.data.frame(apply(bignav[-1,10:ncol(bignav)], 2, function(x) as.integer(as.numeric(x))))
```

```{r}
# Doing the same as the lines above but in one line
bigboynav <- as.data.frame(na.omit(sapply(bignav[-1,10:ncol(bignav)], function(x) as.integer(as.numeric(x)), simplify = TRUE, USE.NAMES = TRUE)))

# Visualizing the response variable with some column of capital invested as potential predictor
ggplot(bigboynav, aes(x=ADC011, y=ACX001)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1000, "k")) +
  theme_bw()


# Checking column alignment
# colnames(bignav[10:ncol(bignav)]) == colnames(bigboynav)

# adding the omitted columns and header row back into bigboynav
bigboynav <- cbind(joiningvariables, bigboynav)
```

```{r}
# I wanted to write the cleaned up data frame into a file.
# install.packages("openxlsx")
library(openxlsx)
write.xlsx(bigboynav, "bigboynav.xlsx")
write.xlsx(bignav, "bignav.xlsx")
```


```{r}
descriptors <- t(bignav[1,])
# `descriptors` is equal to `joiningvariables` transposed
```


```{r}
# ready to split into training and testing data 3:1
set.seed(303)
trows <- sample(x=nrow(bigboynav),size=floor(0.75*nrow(bigboynav)),replace=FALSE)
#separate data
train <- bigboynav[trows,]
test <- bigboynav[-trows,]
```

# The Response Variable
We initially had trouble configuring our data and model to predict the response variable, County Borders Navigable Waterway (ACX001). So we then created new choices for the response variable, namely, peopleSum and capitalSum. We tried building alternate models using these as the response variable, we will explain.

## ACX001 - County Borders Navigable Waterway
Let us build a logistic regression model to predict the presence of (or access to) navigable waterways in a county. We will use the following predictor variables: ADD006 - "Persons employed in inland navigation", ADC014 - "Manufacturing Establishments: Fisheries", ADB004 - "Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced", and ADB013 - "Flour: barrels manufactured". We will use the glm function, binomial family, and ACX001~ADD006+ADC014+ADB004+ADB013+ADE011 formula to build a multiple logistic regression model. As seen above, we have split our data into training and testing sets, for testing our model's performance.

```{r, fig.path="figures/"}
County_Access_Navigable_Waterway <- bigboynav$ACX001
Persons_Employed_Inland_Navigation <- bigboynav$ADD006
Manufacturing_Establishments_Fisheries <- bigboynav$ADC014
Forest_Products_Tar_Pitch_Terpentine_Resin <- bigboynav$ADB004
Flour_Barrels_Manufactured <- bigboynav$ADB013
modelvariables <- bigboynav %>%
  select(ACX001, ADD006, ADC014, ADB004, ADB013)

# Visualizing data we're interested in to learn more about relationships among data set
ADD006 <- ggplot(bigboynav, aes(x=Persons_Employed_Inland_Navigation, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  labs(y = "County_Access_Navigable_Waterway (1=Yes)") +
  theme_bw()
ADD006
ggsave("ADD006.png", plot=ADD006)
```


```{r, fig.path="figures/"}
ADC014 <- ggplot(bigboynav, aes(x=Manufacturing_Establishments_Fisheries, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1e6, "M")) +
  labs(x = "Manufacturing_Establishments_Fisheries (Capital invested in Millions of $USD)", y = "County_Access_Navigable_Waterway (1=Yes)") +
  theme_bw()
ADC014
ggsave("ADC014.png", plot=ADC014)

```


```{r, fig.path="figures/"}
ADB004 <- ggplot(bigboynav, aes(x=Forest_Products_Tar_Pitch_Terpentine_Resin, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1000, "k")) +
  labs(x = "Forest_Products_Tar_Pitch_Terpentine_Resin (Number of Barrels produced, 300~400lbs/barrel)", y = "County_Access_Navigable_Waterway (1=Yes)") +
  theme_bw()
ADB004
ggsave("ADB004.png", plot=ADB004)
```

```{r, include=FALSE}
if (!dir.exists("figures")) {
  dir.create("figures")
}
```
```{r, fig.path="figures/"}
ADB013 <- ggplot(bigboynav, aes(x=Flour_Barrels_Manufactured, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1000, "k")) +
  labs(x = "Flour_Barrels_Manufactured (Number of Barrels produced, 196lbs/barrel)", y = "County_Access_Navigable_Waterway (1=Yes)") +
  theme_bw()
ADB013
ggsave("ADB013.png", plot=ADB013)
```


```{r}
# building logistic regression model using whole dataset
nwmodel <- glm(ACX001~ADD006+ADC014+ADB004+ADB013, data = bigboynav, family = "binomial")
summary(nwmodel)
```
The $p-$values for the predictor variables are all less than 0.05, so we can conclude that there is a significant relationship between the predictor variables and the response variable. Thus we can conclude that our choice of predictor variables was reasonable, at least based on the model trained on the whole data set. There's a statistically significant relationship between a county's access to navigable waterways and the number of people employed in inland navigation, the number of manufacturing establishments in fisheries, and the number of barrels of tar, pitch, turpentine, and resin produced, and the number of barrels of flour produced. Let's look at how this changes when our model is trained on `train`.

```{r}
# building model using train data
nwtmodel <- glm(ACX001~ADD006+ADC014+ADB004+ADB013, data = train, family = "binomial")
summary(nwtmodel)
```
The model trained on the training set has similar results as the one above, but for ADB004, the p-value is now 0.3713, suggesting that the number of barrels of tar, pitch, turpentine, and resin produced is not a significant predictor of a county's access to navigable waterways. This is a good example of how the results of a model can change when the model is trained on different data. To explore our curiosities, we will use both the model trained on the whole data set and one trained on `train` to predict the response variable in the testing set.

# Response Variable Distributions
Let's plot a histogram, even though `County_Access_Navigable_Waterway` is actually a binary variable, we've treated it as a continuous variable with only 0 and 1 as possible values, we will use a histogram(continuous) instead of a barchart(discrete) to visualize the distribution.
```{r}
png("ACX001hist.png")
hist(County_Access_Navigable_Waterway, main = "County Access to Navigable Waterway", xlab = "County Access to Navigable Waterway", ylab = "Number of Counties", breaks=25, col = "lightblue", xaxt = "n")
axis(1, at = c(0, 1), labels = c("No", "Yes"))
dev.off()
```
It seems that about half of the counties do have access to water transportation which would allow for cheaper costs to engage in economic activities. This is a good sign for our model, as we have a good amount of data for both classes of the response variable.


# The Predictor Variables
We have chosen to use the following predictor variables to predict counties' access to navigable waterways:
Let's graph the distributions of these predictor variables to see how they are distributed. We expect to see more skewness in the distributions, unlike the symmetry in the distribution of our response variable ACX001. The data points that skew would be outliers or counties with very high or very low predictor variable values that are not representative of the typical US county circa 1840. We will also look at the correlation between the predictor variables and the response variable to see if there is a relationship between the two. We will use the corrr package to visualize the correlation matrix of the predictor variables and the response variable.

### ADD006 - Persons Employed in Inland Navigation
```{r}
summary(Persons_Employed_Inland_Navigation)
which.max(Persons_Employed_Inland_Navigation)
second <- bigboynav[-900,]
which.max(second$ADD006)
bigboynav[713,]
```
```{r}
png("ADD006hist.png")
hist(Persons_Employed_Inland_Navigation, main = "Persons Employed in Inland Navigation", xlab = "Persons Employed in Inland Navigation", ylab = "Number of Counties", col = "lightblue")
dev.off()
```
The extreme outliers belong to Hamilton, Ohio, and St Louis, Missouri. These are major cities and are not representative of the typical US county.

### ADC014 - Manufacturing Establishments: Fisheries
```{r}
max(Manufacturing_Establishments_Fisheries)
```
With $5980800 invested in fisheries, this is an extreme outlier. This is Bristol, Massachusetts, a major city and not representative of the typical US county.

```{r}
png("ADC014hist.png")
hist(Manufacturing_Establishments_Fisheries, main = "Manufacturing Establishments: Fisheries", xlab = "Manufacturing Establishments: Fisheries (Capital invested in Millions of $USD)", ylab = "Number of Counties", col = "lightblue", xaxt = "n", breaks=60)
axis(1, at = breaks, labels = paste0(breaks/1e6, "M"))
dev.off()
```

```{r}
png("ADC014hist2.png")
hist(Manufacturing_Establishments_Fisheries, main = "Manufacturing Establishments: Fisheries", xlab = "Manufacturing Establishments: Fisheries (Capital invested in $USD (not millions))", ylab = "Number of Counties", col = "lightblue", breaks=15000, xlim=c(0, 3000), xaxt='n')
axis(1, at = seq(0,3000,100), labels = paste0(seq(0,3000,100)))
dev.off()
```
Even when zoomed in to just (0,3000) on the x-axis, the histogram isn't very helpful. There seems to be an extreme outlier.


### ADB004 - Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced
```{r}
png("ADB004hist.png")
hist(Forest_Products_Tar_Pitch_Terpentine_Resin, main = "Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced", xlab = "Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced", ylab = "Number of Counties", col = "lightblue")
dev.off()
```
Again, there's an extreme outlier. This time it's New Hanover, North Carolina, a major city and not representative of the typical US county.
```{r}
png("ADB004hist2.png")
hist(Forest_Products_Tar_Pitch_Terpentine_Resin, main = "Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced", xlab = "Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced", ylab = "Number of Counties", col = "lightblue", breaks=1500, xlim=c(0, 1500), xaxt='n')
axis(1, at = seq(0,1500,300), labels = paste0(seq(0,1500,300)))
dev.off()
```
This histogram is more helpful in visualizing the non-outlier data.

### ADB013 - Flour: barrels manufactured
```{r}
png("ADB013hist.png")
hist(Flour_Barrels_Manufactured, main = "Flour: barrels manufactured", xlab = "Flour: barrels manufactured", ylab = "Number of Counties", col = "lightblue", breaks=150, xlim=c(0, 50000), xaxt='n')
axis(1, at = seq(0,50000,5000), labels = paste0(seq(0,50000,5000)))
dev.off()
```
```{r}
max(Flour_Barrels_Manufactured)
which.max(Flour_Barrels_Manufactured)
bigboynav[774,]

```

# Association between Predictor Variables and Response Variable
```{r}
cor(County_Access_Navigable_Waterway, Persons_Employed_Inland_Navigation)
cor(County_Access_Navigable_Waterway, Manufacturing_Establishments_Fisheries)
cor(County_Access_Navigable_Waterway, Forest_Products_Tar_Pitch_Terpentine_Resin)
cor(County_Access_Navigable_Waterway, Flour_Barrels_Manufactured)
```
The correlation between the response variable and the predictor variables is weak, with the highest correlation being 0.2. This is not a good sign for our model, as we want to see a strong correlation between the predictor variables and the response variable. This may be because of the distribution of our response, or the simple variability between counties.
Let's create a correlation matrix for a better visualization.
```{r}
cor(modelvariables)
```
And graphs.
```{r}
png("predictorsassociation.png")
pairs(modelvariables)
dev.off()
```

The correlation matrix and the scatterplots confirm that there is no strong correlation between the predictor variables and the response variable. Again, this is not a good sign for our model, but this may be because of the distribution of our response, or the simple variability between counties.

# Distributions of the Predictor Variables
The distributions of the predictor variables are all right-skewed, with the exception of Manufacturing Establishments: Fisheries, which has an extreme outlier. This is not a good sign for our model, as we want to see more symmetry in the distributions of the predictor variables. This may be because of the simple variability between counties, or the presence of extreme outliers.

# The Null Model

The RMSE of the null model of the training set, the mean, used on the testing set is roughly 4600, meaning that on average the null model is 4600 people of from the correct amount of people working in the county. Considering that many counties are clustered around having roughly 5,000 people working, this is a high RMSE. This makes sense as the mean is pulled high but the right skew of peopleSum.

```{r}
# testing %>% summarize(rmseNull = sqrt(mean((peopleSum-mean(training$peopleSum))^2)))
```
