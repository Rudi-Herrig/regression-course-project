---
title: "Project Paper 1"
author: "Rudi Herrig and Jordan Kim"
date: "17 March 2024"
output:
  pdf_document: default
---

```{r setup, include=FALSE}
library(knitr)
library(tinytex)
library(readxl)
library(tidyverse)
library(stringr)
library(magrittr)
library(ggplot2)
# install.packages("corrr")
library(corrr)
# install.packages("corrplot")
library(corrplot)

knitr::opts_chunk$set(echo = FALSE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(out.width = "100%",fig.align='center')
```

```{r}
# I have split our code into chunks to make it easier to see which code does what
# I have also commented the code to make it easier to understand

# 1280 rows
# ADB - production of industries
# ADE - Men employed in selected industries
production <- read_xlsx("USCensus_1840_county.xlsx")
# to check for data structure, `summary(production)` is used

# 1280 rows
# ACX - County Borders Navigable waterway, 1 if yes
navig <- read_xlsx("USCensusData1840.xlsx")
# There was an extra row in `navig` for D.C.'s county of Alexandria (distinct from Rural County of Alexandria) so I removed it.
navig <- navig[-101,]

# 1280 rows
# ADC - Capital Invested
# ADD - Persons Employed
capital <- read_xlsx("USCensusData1840_2.xlsx")
```

```{r}
# bigboy is all the data sets combined
bigboy <- production %>% inner_join(navig) %>% inner_join(capital) 

# bignav is to try to salvage the navigable waterway variable as the response
bignav <- navig %>%  inner_join(capital) %>% inner_join(production)
# I omit all rows with NAs
bignav <- na.omit(bignav)
# bignav has 1257 rows (including Header row) after NA rows are removed
# separating header row to further clean up the data set
bignav_head <- bignav %>% slice_head()
# joiningvariables is the data frame for the rows used for joining (i.e. same as bigboy[,1:9])
joiningvariables <- bignav[-1, 1:9]
# I apply as.numeric and as.integer functions to convert columns to integers
# I apply function to without the header row of the data set and the non-meaningful columns 
bignavnumconv <- as.data.frame(apply(bignav[-1,10:ncol(bignav)], 2, function(x) as.integer(as.numeric(x))))
```

```{r}
# Doing the same as the lines above but in one line
bigboynav <- as.data.frame(na.omit(sapply(bignav[-1,10:ncol(bignav)], function(x) as.integer(as.numeric(x)), simplify = TRUE, USE.NAMES = TRUE)))

# Visualizing the response variable with some column of capital invested as potential predictor
ggplot(bigboynav, aes(x=ADC011, y=ACX001)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1000, "k")) +
  theme_bw()


# Checking column alignment
# colnames(bignav[10:ncol(bignav)]) == colnames(bigboynav)

# adding the omitted columns and header row back into bigboynav
bigboynav <- cbind(joiningvariables, bigboynav)
```
```{r}
str(colnames(bigboynav[1]))
str(colnames(bigboynav)[1])
bigboynav
```

```{r}
# I wanted to write the cleaned up data frame into a file.
# install.packages("openxlsx")
library(openxlsx)
write.xlsx(bigboynav, "bigboynav.xlsx")
write.xlsx(bignav, "bignav.xlsx")
```


```{r}
descriptors <- t(bignav[1,])
# I want to be able to refer to the columns with these names
# for (i in 122) {
#   bignav_head[,i] = bignav_head(colnames(bignav_head)[i])
# }
#
# colnames(bignav)[1,i] = bignav

```


```{r}
# ready to split into training and testing data 3:1
set.seed(303)
trows <- sample(x=nrow(bigboynav),size=floor(0.75*nrow(bigboynav)),replace=FALSE)
#separate data
train <- bigboynav[trows,]
test <- bigboynav[-trows,]
```

```{r}
# I seperate the header descriptions into a seperate variable, then clean bigboy up a bit
bigboy_head <- bigboy %>% slice_head()
bigboy %<>% slice(-1) %>% select(-YEAR) %>% 
  mutate(across(starts_with(c("ad", "ac")), as.numeric))

bigboy %<>% mutate(menSum = rowSums(across(starts_with("ADE")))) %>%
  mutate(peopleSum = rowSums(across(starts_with("ADD"))))  %>% 
  mutate(capitalSum = rowSums(across(starts_with("ADC"))))



#remove all rows with NA values
bigboy <- bigboy[!rowSums(is.na(bigboy)),]

set.seed(303)
rows <- sample(x=nrow(bigboy),size=floor(0.75*nrow(bigboy)),replace=FALSE)

#separate data
training <- bigboy[rows,]
testing <- bigboy[-rows,]
```

# The Response Variable
We initially had trouble configuring our data and model to predict the response variable, County Borders Navigable Waterway (ACX001). So we then created new choices for the response variable, namely, peopleSum and capitalSum. We will explain.

## ACX001 - County Borders Navigable Waterway
Let's build a logistic regression model to predict the presence of navigable waterways in a county. We will use the following predictor variables: ADD006 - "Persons employed in inland navigation", ADC014 - "Manufacturing Establishments: Fisheries", ADB004 - "Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced", and ADB013 - "Flour: barrels manufactured". We will use the glm function, binomial family, and ACX001~ADD006+ADC014+ADB004+ADB013+ADE011 formula to build a multiple logistic regression model. As seen above, we have split our data 80-20 into training and testing sets, for testing our model's performance.
```{r}
County_Access_Navigable_Waterway <- bigboynav$ACX001
Persons_Employed_Inland_Navigation <- bigboynav$ADD006
Manufacturing_Establishments_Fisheries <- bigboynav$ADC014
Forest_Products_Tar_Pitch_Terpentine_Resin <- bigboynav$ADB004
Flour_Barrels_Manufactured <- bigboynav$ADB013
# Visualizing data we're interested in to learn more about relationships among data set
ggplot(bigboynav, aes(x=Persons_Employed_Inland_Navigation, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  theme_bw()
```


```{r}
ggplot(bigboynav, aes(x=Manufacturing_Establishments_Fisheries, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1e6, "M")) +
  labs(x = "Manufacturing_Establishments_Fisheries (Capital invested in Millions of $USD)") +
  theme_bw()
```


```{r}
ggplot(bigboynav, aes(x=Forest_Products_Tar_Pitch_Terpentine_Resin, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1000, "k")) +
  labs(x = "Forest_Products_Tar_Pitch_Terpentine_Resin (Number of Barrels produced, 300~400lbs/barrel)") +
  theme_bw()
```


```{r}
ggplot(bigboynav, aes(x=Flour_Barrels_Manufactured, y=County_Access_Navigable_Waterway)) +
  geom_point() +
  geom_jitter(height=0.05,size=2,alpha=0.2) +
  scale_y_continuous(breaks = c(0, 1)) +
  scale_x_continuous(labels = function(x) paste0(x / 1000, "k")) +
  labs(x = "Flour_Barrels_Manufactured (Number of Barrels produced, 196lbs/barrel)") +
  theme_bw()
```


```{r}
# building logistic regression model using whole dataset
nwmodel <- glm(ACX001~ADD006+ADC014+ADB004+ADB013, data = bigboynav, family = "binomial")
summary(nwmodel)
```
The $p-$values for the predictor variables are all less than 0.05, so we can conclude that there is a significant relationship between the predictor variables and the response variable. Thus we can conclude that our choice of predictor variables was reasonable, at least based on the model trained on the whole data set. There's a statistically significant relationship between a county's access to navigable waterways and the number of people employed in inland navigation, the number of manufacturing establishments in fisheries, and the number of barrels of tar, pitch, turpentine, and resin produced, and the number of barrels of flour produced. Let's look at how this changes when our model is trained on `train`.

```{r}
# building model using train data
nwtmodel <- glm(ACX001~ADD006+ADC014+ADB004+ADB013, data = train, family = "binomial")
summary(nwtmodel)
```
The model trained on the training set has similar results as the one above, but for ADB004, the p-value is now 0.3713, suggesting that the number of barrels of tar, pitch, turpentine, and resin produced is not a significant predictor of a county's access to navigable waterways. This is a good example of how the results of a model can change when the model is trained on different data. To explore our curiosities, we will use both the model trained on the whole data set and one trained on `train` to predict the response variable in the testing set.

# what to do with section below TBD. Will ask Dr. Pruitt if we may build multiple models using the 3 response variable choices.
In this paper, we have decided to study the response variable peopleSum, which we have created by summing all of the columns in the data that measure how many people work in each industry in a county. Importantly, this sum is distinct from the total amount of men employed in each county, which are counted by different columns. The amount of men working in each county and the amount of people working in each county is distinct. peopleSum sums across the columns indicating Persons Working in Mining, Agriculture, Commerce, Manufacturing, Ocean Navigation, Inland Navigation and "Proffesions" (laywers, politicians etc.). As such, it represents the total amount of people in the county who were employed in 1840. The response variable is distributed with a strong right skew, with most counties having under 10,000 people working, but a few outliers with more than 20,000 people working.

```{r}
ggplot(data = bigboy, aes(x=peopleSum)) +
  geom_histogram() +
  theme_bw()
```

# The Predictor Variables
We have chosen to use the following predictor variables to predict counties' access to navigable waterways:
### ADD006 - Persons Employed in Inland Navigation
### ADC014 - Manufacturing Establishments: Fisheries
### ADB004 - Forest Products: Tar, Pitch, Turpentine and Resin: Barrels Produced
### ADB013 - Flour: barrels manufactured
The first predictor variable we examine is capitalSum, the total amount of capital invested in the county. It is somewhat moderately correlated with our response variable. Our second predictor variable is the number of weekly newspapers produced in the county (ADB028), which is again moderately correlated with our response variable. This makes intuitive sense, as the number of weekly newspapers might reflect the total population of the town, which would be highly correlated with the amount of people working in the county. Our third predictor variable is the amount of men employed in making carriages in the county (ADE033), which again is moderately correlated with our response variale. Our fourth predictor variable is the amount of men employed in residential contruction in the county(ADE036), which is moderately correlated with our response variable. All of these response variables have only moderate correlations, but they are the strongest individual predictors I have found. This may be because of the distribution of our response, or the simple variability between counties.

```{r}
modelWork <- lm("peopleSum ~ capitalSum", data = training)
summary(modelWork)

# modelWork2 was referenced below summary(modelWork2) but undefined
modelWork2 <- lm("peopleSum ~ capitalSum", data = training)

modelNews <-lm("peopleSum ~ ADB023", data = training)
summary(modelWork2)



modelCarriage <-lm("peopleSum ~ ADE033", data = training)
summary(modelWork2)

modelConstr <-lm("peopleSum ~ ADE036", data = training)
summary(modelWork2)

```

# The Null Model

The RMSE of the null model of the training set, the mean, used on the testing set is roughly 4600, meaning that on average the null model is 4600 people of from the correct amount of people working in the county. Considering that many counties are clustered around having roughly 5,000 people working, this is a high RMSE. This makes sense as the mean is pulled high but the right skew of peopleSum.

```{r}
testing %>% summarize(rmseNull = sqrt(mean((peopleSum-mean(training$peopleSum))^2)))
```
